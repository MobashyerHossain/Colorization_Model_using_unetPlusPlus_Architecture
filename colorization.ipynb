{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ml package Inports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.datasets import ImageNet\n",
    "from torchvision.transforms import ToTensor\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torch.utils.data import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper package Imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from zipfile import ZipFile\n",
    "import os\n",
    "import glob\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "import splitfolders\n",
    "import time\n",
    "from tqdm.notebook import tqdm, trange\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting Dataset and renameing folder\n",
    "if not Path(\"./Data/\").is_dir() :\n",
    "    with ZipFile('archive_5.zip',\"r\") as z:\n",
    "        z.extractall(path=\"./Data/\")\n",
    "    old_name = str(os.listdir('./Data/')[0])\n",
    "    os.renames('./Data/'+old_name, './Data/'+'Input')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data directories\n",
    "input_dir = './Data/Input/'\n",
    "output_dir = './Data/Output/'\n",
    "if not os.path.exists(output_dir):\n",
    "    os.mkdir(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Images : 10800\n",
      "Sample Image Name : 000000010218.jpg\n"
     ]
    }
   ],
   "source": [
    "# filename check\n",
    "imgs = os.listdir(input_dir)\n",
    "print(f'Total Images : {len(imgs)}')\n",
    "print(f'Sample Image Name : {imgs[5]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4357ffd5be7e48a7a29ba3abcf493513",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=10800.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# change images\n",
    "if os.path.exists(output_dir):\n",
    "    for i in trange(len(imgs)):\n",
    "        imgName = imgs[i]\n",
    "        img = Image.open(input_dir+imgName).convert('LA')\n",
    "        img.save(output_dir+imgName.replace('.jpg', '.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change one image\n",
    "# img = Image.open(data_dir+imgs[0]).convert('LA')\n",
    "# img.save(imgs[0].replace('.jpg', '.png'))\n",
    "# img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into train, validation and test data\n",
    "def split_indices(n, val_pct, test_pct):\n",
    "    # determine the size of the validation set, test set\n",
    "    n_val = int(val_pct*n)\n",
    "    n_test = int(test_pct*n + n_val)\n",
    "    # print(n_val, n_test, n_train)\n",
    "    # create random parmutation of 0 to n-1\n",
    "    idxs = np.random.permutation(n)\n",
    "    # pick data as train[start-val], validation[val-test] and test[test-end]\n",
    "    return idxs[n_test:], idxs[:n_val], idxs[n_val:n_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "?ImageFolder.make_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformer\n",
    "img_transform = transforms.Compose([\n",
    "    transforms.CenterCrop(300),\n",
    "#     transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
    "    transforms.ToTensor(),])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataSet\n",
    "ImageData = ImageFolder('Data/',\n",
    "                      transform = img_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        Training Images   : 5800\n",
      "\n",
      "        Validation Images : 1656\n",
      "\n",
      "        Testing Images    : 828\n",
      "\n",
      "        Total Images      : 8284\n"
     ]
    }
   ],
   "source": [
    "# split the dataset into training, validation and test set\n",
    "train_indices, val_indices, test_indices = split_indices(len(dataset), 0.2, 0.1)\n",
    "print(f\"\"\"\n",
    "        Training Images   : {len(train_indices)}\\n\n",
    "        Validation Images : {len(val_indices)}\\n\n",
    "        Testing Images    : {len(test_indices)}\\n\n",
    "        Total Images      : {len(train_indices) + len(val_indices) + len(test_indices)}\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyper parameter\n",
    "batch_size=50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training sampler and dataloader\n",
    "train_sampler = SubsetRandomSampler(train_indices)    # takes samples w.r.t the indices\n",
    "train_dl = DataLoader(dataset,\n",
    "                      batch_size,\n",
    "                      sampler = train_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validation sampler and dataloader\n",
    "val_sampler = SubsetRandomSampler(val_indices)        # takes samples w.r.t the indices\n",
    "val_dl = DataLoader(dataset,\n",
    "                    batch_size,\n",
    "                    sampler = val_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test sampler and dataloader\n",
    "test_sampler = SubsetRandomSampler(test_indices)        # takes samples w.r.t the indices\n",
    "test_dl = DataLoader(dataset,\n",
    "                     batch_size,\n",
    "                     sampler = test_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-159-4edf451545fc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtrain_dl\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create grayscale from color images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # get device function\n",
    "def get_device():\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device('cuda')\n",
    "    else:\n",
    "        return torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set device\n",
    "device = get_device()\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyper parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
